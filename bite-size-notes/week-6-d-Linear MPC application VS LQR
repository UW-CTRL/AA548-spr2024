# Linear Model Predictive Control algorithm and Comparison with LQR
 
## Scope and Objectives
This note will summarize the function of Linear Model Predictive Control to solve the tracking problem. It will also gives an example in the real applications. This note will also discuss briefly about the advantages and disadvantages of this control compared to LQR Control Model

## Introduction
The Linear Model Predictive Control (LMPC) is a one of the most frequently used control method designed for dynamic systems, such as autonomous vehicles. It is widely used because it balances the simplicity of open-loop control and the precision of full closed-loop control. Unlike open-loop systems, LMPC adapts to changes in system dynamics and disturbances through predictive modeling, enhancing its robustness and accuracy. While if we Compared to fully closed-loop control, LMPC uses a predictive horizon that optimizes performance and reduces unnecessary computation while maintaining stability. This control model helps anticipate and mitigate potential system constraints or disturbances and keep the system stable, offering a superior control solution that is both efficient and adaptable.

## Preliminaries
Before going to the application of Linear MPC to solve tracking problems, here are a few basic things we need to know :

### System Model
In Linear MPC, we use a linear time-invariant (LTI) system model described by the state-space equations:
$$
x_{k+1} = A x_k + B u_k + w_k
$$
where:
- $x_k$ is the state vector at time step $k$,
- $u_k$ is the control input at time step $k$,
- $w_k$ is the noise vaariable
- $A$ and $B$ are system matrices defining the dynamics. $A$ and $B$ values can also be time vaarying, thus making it as $A_k$ and $B_k$

### Objective Function
MPC is usually modeled as typical quadratic form of cost function with linear dynamics. The objective is to minimize a cost function over a finite prediction horizon:
$$
J = \sum_{k=0}^{N-1} \left( x_k^T Q x_k + u_k^T R u_k \right) + x_N^T P x_N
$$
where:
- $N$ is the prediction horizon,
- $Q$, $R$, and $P$ are the weighting matrices for the states and control inputs,
- $x_N$ is the state at the end of the prediction horizon, and $P$ is the terminal weight matrix.
- The sum part is usually called cost to go and the cost at the final time step is called the terminal cost

### Constraints
Linear MPC can incorporate various constraints to ensure the system's control actions are feasible and safe:
$$
u_{\text{min}} \leq u_k \leq u_{\text{max}}
$$
$$
x_{\text{min}} \leq x_k \leq x_{\text{max}}
$$

### Predictive Model
Using the system model, future states are predicted based on the current state and future control inputs, allowing the controller to anticipate and adjust to system dynamics and disturbances.

### Optimization Problem & Receding Horizon Principle
At each control step, MPC solves an optimization problem to determine the optimal control actions:
$$
\min_{U} \left\{ \sum_{k=0}^{N-1} \left( x_k^T Q x_k + u_k^T R u_k \right) + x_N^T P x_N \right\}
$$
Subject to:
$$
x_{k+1} = A x_k + B u_k + w_k 
$$
$$
u_{\text{min}} \leq u_k \leq u_{\text{max}}
$$
$$
x_{\text{min}} \leq x_k \leq x_{\text{max}}
$$
where $U$ is the sequence of future control inputs over the prediction horizon.

**MPC only implements the first control input from the optimized sequence, then updates the state based on this input and recalculates the optimal path at the next timestep, continuously adapting to new data.**

This structured approach allows LMPC to efficiently manage system responses while adhering to constraints, providing a robust method for control that balances performance with computational practicality.

## Main Body
### Below is a simple diagram showing how the MPC works :
![MPC Control Algorithm](https://github.com/1997Theo/streamlit_bank_campaign/blob/main/mpcalgorithm.png?raw=True)
#### *Fig 1 MPC Control Algorithm*</br></br>
Here is a brief explanation on pictures above :
- **Reference/desired state:**
This is the desired trajectory or setpoints that the control system aims to achieve. These could be speed, position, temperature, etc., depending on the specific application of the MPC.
- **MPC Controller:**
The central component of the diagram, consisting of two main sub-components:
- **Optimizer:**
This calculates the optimal control inputs by solving a constrained optimization problem. The objective is usually to minimize the difference between the predicted outputs and the reference over the prediction horizon, while also minimizing the use of control energy.
- **Prediction Model:**
This model predicts future outputs of the system based on current and past information and the proposed control inputs. It usually encompasses the dynamics of the vehicle or process being controlled.
- **Control Inputs:**
These are the actions or commands generated by the optimizer that are sent to the vehicle or process. These inputs are designed to drive the system towards the reference objectives.
- **Vehicle:**
This represents the physical system or process being controlled by the MPC. In this context, it's labeled as a "vehicle," which could be literal (such as a car or drone) or figurative (such as any system that 'moves' or changes state).
- **Measured Outputs:**
These are the actual outputs from the vehicle or process, which are fed back into the MPC controller. This feedback loop allows the MPC to update its predictions and optimize future control inputs, adjusting for any discrepancies between the predicted and actual outputs.


## MPC VS LQR application
As we have learned about LQR in the previous section, now we want to see the strength and weakness of this MPC model compared to LQR algorithm :
#### **Linear Quadratic Regulator (LQR)**
LQR is a feedback control strategy designed for linear systems and aims to minimize a quadratic cost function that represents the error (deviation from the desired state) and the control effort. The solution to the LQR problem involves solving an algebraic Riccati equation to find an optimal gain matrix \( K \). This gain matrix is used to compute the control input as \( u = -Kx \), where \( x \) is the state vector of the system.

#### **Model Predictive Control (MPC)**
MPC solves an optimization problem at each step in the control process. It uses a model of the system to predict future states over a finite horizon based on current states and a sequence of future control inputs. The objective is to minimize a cost function typically similar to LQR but over a finite horizon and subject to constraints on states and controls. After solving the optimization, only the first control action is implemented, and the process is repeated at the next step.

#### Advantages of Using MPC Over LQR
- **Better at handling constraints on inputs and states,** ensuring compliance with operational limits.
- **Adapts in real-time to changes and disturbances,** improving system responsiveness and robustness.
- **Utilizes predictive capabilities to anticipate future events,** optimizing control actions proactively.

#### Disadvantages of Using MPC Over LQR
- **Requires significant computational resources,** which can be a constraint in real-time applications.
- **Implementation complexity is higher** due to the need for solving optimization problems frequently.
- **Relies heavily on model accuracy,** with performance degrading if the predictive model is not precise.

### MPC VS LQR Implementation Example
Now, we are going to implement MPC algorithm into Homework 2 Problem 3 where we did it with LQR before. Because MPC has a variable called N_horizon (how many time step do we want to predict), this note will take 2 N_horizon of prefiction which is 10 and N (total time step). The code snippets is only a close loop part of homework 2 problem 3, everything else is in HW 2 starter code using N_horizon = 10. (If you want to practice, simply change the N_horizon at the bottom of the code) :
```
A = []
B = []

Q = 1e3 * np.diag([1, 1e-2, 1, 1e-2, 1e-2, 1e-2])
R = np.diag([1, 1])


def linearize_autodiff(unicycle_dynamics, state, control, dt):

    A = jacfwd(unicycle_dynamics, argnums=0)(state, control, dt)
    B = jacfwd(unicycle_dynamics, argnums=1)(state, control, dt)
    return A, B

for k in range(N):
    a,b = linearize_autodiff(BasePlanarQuadrotor().discrete_step, nominal_states[k], nominal_controls[k], dt)
    A.append(a)
    B.append(b)
```

```
def simulate_closed_loop(initial_state, nominal_states, nominal_controls, N_horizon):
    states = [initial_state]
    n = 6
    m = 2
    objective = 0
    for k in range(N):
        current_state = states[k]
        current_state = current_state.reshape(-1, 1)

        # Set up the MPC optimization problem
        x = {i: cp.Variable((n, 1)) for i in range(N_horizon + 1)}  # State variables over horizon
        u = {i: cp.Variable((m, 1)) for i in range(N_horizon)} 
        
        constraints = [x[0] == current_state]
        
        for t in range(N_horizon):
            if t + k >= 50 :
                objective += cp.Minimize(
                    cp.quad_form(x[t] - nominal_states[t+k].reshape(-1, 1), Q) # terminal cost
                )
                break
            else :
                # Define the system dynamics and constraints
                objective += cp.Minimize(
                    cp.quad_form(x[t] - nominal_states[t+k].reshape(-1, 1), Q)  +
                    cp.quad_form(u[t] - nominal_controls[t+k].reshape(-1,1), R)
                )

                # Dynamics constraint, for simplicity using linear dynamics, replace with your system
                constraints.append(x[t+1] == A[t+k] @ x[t] + B[t+k] @ u[t])  # A, B should be defined based on your model
                constraints.append(u[t] >= planar_quad.min_thrust_per_prop)  # control input constraints
                constraints.append(u[t] <= planar_quad.max_thrust_per_prop)

        # Solve the MPC problem
        prob = cp.Problem(objective, constraints)
        prob.solve(solver=cp.ECOS, verbose=True)

        # Extract the optimal control to apply
        optimal_control = u[0].value.T + nominal_controls[k]


        next_state = planar_quad.discrete_step(states[k], optimal_control.reshape(-1,), dt)
        next_state = apply_wind_disturbance(next_state, dt)
        states.append(next_state)

    return np.array(states)


planar_quad = PlanarQuadrotor()
fig, ax = plt.subplots(figsize=(12, 6))
plot_obstacle(ax)
plot_nominal_trajectory(ax)
plot_wind(ax)
planar_quad.animate(simulate_closed_loop(initial_state, nominal_states, nominal_controls, 10), dt, ax)
```
Here is the comparison result of the simulation :
### 1. LQR Control (3 seconds to run)
![LQR_simulation_Result](https://github.com/1997Theo/AA548-spr2024/blob/main/bite-size-notes/figs/lqr.png?raw=True)
#### *Fig 2 LQR Simulation Result*</br></br>


### 2. MPC with N_horizon = 10 Control (1 minute 22 seconds to run)
![LQR_simulation_Result](https://github.com/1997Theo/AA548-spr2024/blob/main/bite-size-notes/figs/MPC_10.png?raw=True)
#### *Fig 3 MPC Simulation with N_horizon = 10*</br></br>


### 3. MPC with N_horizon = 50 Control (4 minutes 29 seconds to run)
![LQR_simulation_Result](https://github.com/1997Theo/AA548-spr2024/blob/main/bite-size-notes/figs/MPC_50.png?raw=True)
#### *Fig 4 MPC Simulation with N_horizon = 50*</br></br>

From that simulation, we could see that MPC took longer time to run because it evaluates the overall optimization (equal to the number of N_horizon) for each time steps. The further we want the prediction, the longer it will take time. In this case, we could see that LQR result is better than MPC for both 10 and 50 N_horizon. Even 10 N_horizon is better than 50 N_horizon. This is because The performance of MPC is heavily dependent on the accuracy of the system model. An inaccurate model can lead to suboptimal control.

## Conclusion on Model Predictive Control (MPC)
Model Predictive Control (MPC) is a sophisticated control strategy that offers significant advantages in complex and constrained environments. It excels in systems where the ability to adhere to operational constraints and respond adaptively to changes in system dynamics is crucial. The predictive nature of MPC allows for proactive management of system responses, leveraging its capability to forecast future conditions and optimize control actions accordingly.

However, the benefits of MPC come with certain trade-offs. The requirement for significant computational resources and the complexity of implementation are considerable challenges, especially in environments demanding real-time decision-making. Moreover, the effectiveness of MPC is heavily reliant on the accuracy of the underlying model used for predictions. Any discrepancies between the model and actual system behavior can lead to suboptimal control decisions.



## Reference :
[1] Design and Experimental Comparison of PID, LQR and MPC Stabilizing Controllers for Parrot Mambo Mini-Drone,
Mohamed Okasha and Jordan K. Kralev and Maidul Islam,2022,
url={https://api.semanticscholar.org/CorpusID:249301956} </br>
[2] Leung, Karen. “Linear Multivariable Control” Lecture, University of Washington, Seattle, 2024-04-02. </br>
[3] M. Islam and M. Okasha, "A Comparative Study of PD, LQR and MPC on Quadrotor Using Quaternion Approach," 2019 7th International Conference on Mechatronics Engineering (ICOM), Putrajaya, Malaysia, 2019, pp. 1-6, url={https://ieeexplore.ieee.org/document/8952046} </br>
[4] Stanford Lectures on MPC https://stanford.edu/class/ee365/lectures/mpc.pdf
