{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Path From LQG to Robust Control Theory\n",
    "Bite-Sized Notes\\\n",
    "Sam Vial\\\n",
    "22 May 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "At the beginning of week eight, we finally had all of the pieces in place for a Linear Quadratic Gaussian (LQG) system.  An LQG system combines a linear quadratic regulator (LQR) control scheme with a Kallman filter state estimator. We had proven that for a system with linear dynamics and a quadratic cost function an LQR provided optimum controls to minimize the quadratic cost.  Likewise we had shown that a Kallman filter was an optimum state estimator (minimizing uncertainty) for these systems. Via the Separation Prinicipal we showed that LQR and Kallman filters maintained their optimality when combined. We had even learned how to approximate linear dynamics and quadratic cost functions for systems without them so that they might get in on this good thing we have going. \n",
    "\n",
    "Indeed much of the quarter was spent assembling, piece by piece, the tools necessary to implement LQG systems. Where do you go from this lofty perch of optimality?  Consider the question, \"With respect to what is LQG an optimal control/estimation framework?\"  Or more to the point, \"In what ways are LQG schemes not optimal?\" One answer came in a famously terse article published in 1978 by John Doyle [1]. Doyle titled his article, *Guaranteed Margins for LQG Regulators*. The abstract reads simply: \"There are none.\"\n",
    "\n",
    "These notes will examine Doyle's findings, discuss what they say about the stability of LQG systems, and see why they offer a natural transition from state space controls to the frequency domain and the field of robust control theory. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Example of LQG Fragility\n",
    "\n",
    "##### Define The System\n",
    "Boyle exposes the vulnerability of LQG systems by exploring an example.  Consider the simple system shown below.  The system has linear dynamics, one dimension controls, and gaussian white noise process disturbance.  You can see that only $x_1$ is measured, and the measurement is also subject to gaussian white noise.\n",
    "\n",
    "\n",
    "$$\n",
    "\\dot{x} = \\begin{bmatrix}\n",
    "\\dot{x}_1 \\\\\n",
    "\\dot{x}_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "u\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "w\n",
    "$$\n",
    "\n",
    "$$\n",
    "y = \\begin{bmatrix}\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{bmatrix}\n",
    "+ v\n",
    "$$\n",
    "\n",
    "Here, our process noise and gaussian noise are $w \\sim \\mathcal{N}(0, \\sigma_w)$ and $v \\sim \\mathcal{N}(0, \\sigma_v) $, respectively, and $\\sigma_w < 0$, $\\sigma_v = 0$.  If you consider the vector of $w$'s to be its own random variable, $ \\mathbf{w} \\sim \\mathcal{N}(0, S_w)$ the system may be represented as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\dot{x} &= Ax + Bu + w \\\\\n",
    "\\dot{y} &= Cx + v\n",
    "\\end{align*}\n",
    "\n",
    "Note: Even though $v$ is a scalar random variable, we will refer to the covariance of $v$ as $S_v$ later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build LQG\n",
    "To construct an LQG system, we will need a $Q$ and $R$ for our cost function. We will use simple stand-ins.\n",
    "\n",
    "$$\n",
    "\n",
    "\\begin{align*}\n",
    "R &= 1 \\\\\n",
    "Q &= q \\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\n",
    "Here $q>0$. Great.  Now, we may begin building our LQG. We will Start by finding the cost matrix $P$ using the continuous time infinite horizon Algebraic Riccati Equation (ARE):\n",
    "\n",
    "$$\n",
    "\n",
    "\\dot{P} = A^TP + PA - PBR^{-1}B^TP + Q = 0\n",
    "\n",
    "$$\n",
    "\n",
    "It is presumed that $\\dot{P}$ goes to 0 over time. The code cell below solves the ARE for $P$ numerically.  We may then use $P$ to solve for our control gain, $K = R^{-1}B^TP$, such that $u = -Kx$. The code below also performs this step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steady state P:\n",
      "[[9.  4.5]\n",
      " [4.5 4.5]]\n",
      "Control Gain K:  [-4.5 -4.5]\n",
      "Analytically derived K:  [-4.5 -4.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# Define matrices and variables\n",
    "A = np.array([[1.0, 1.0], [0.0, 1.0]])\n",
    "B = np.array([[0.0], [1.0]])\n",
    "q = 2.25\n",
    "Q = q*np.ones((2,2))\n",
    "R = np.array([[1.0]])\n",
    "\n",
    "\n",
    "# Solve the continuous time ARE for P\n",
    "P = sp.linalg.solve_continuous_are(A, B, Q, R)\n",
    "print(\"Steady state P:\")\n",
    "print(P)\n",
    "\n",
    "# Solve for control gain K\n",
    "K = B.T@P\n",
    "print(\"Control Gain K: \", K[0])\n",
    "\n",
    "# Check against analytic solution\n",
    "K_a = (2 + np.sqrt(4+q)) * np.ones(2)\n",
    "print(\"Analytically derived K: \", K_a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boyle somehow derived an analytic solution for the control gain (presumably using the time he saved for writing an abstract).  He came up with:\n",
    "$$\n",
    "K = (2 + \\sqrt{4+q})\\begin{bmatrix}\n",
    "1 & 1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The above code computes and displays this analytic solution for comparison to our numerical soluton (given same q).  We can confirm that we are on the right track. \n",
    "\n",
    "Next, we will do basically the same thing, but on the estimator side of our LQR.  We will solve an ARE for the steady state $\\Sigma$, and then solve for our Kallman filter gain, $L = \\Sigma C^T S_v^{-1}$. The ARE in this case is\n",
    "$$\n",
    "\\dot{\\Sigma} = A\\Sigma + \\Sigma A^T - \\Sigma C^T S_v^{-1} C \\Sigma + S_w = 0\n",
    "$$\n",
    "\n",
    "Doyle's Analytic solution for the Kallman filter gain was\n",
    "$$\n",
    "L = (2 + \\sqrt{4+\\sigma_w})\\begin{bmatrix}\n",
    "1 \\\\ \n",
    "1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The code below solves this second ARE for $\\Sigma$, calculates $L$ numerically, and then displays Boyle's analytic solution for confirmation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steady state Sigma:\n",
      "[[ 5.  5.]\n",
      " [ 5. 10.]]\n",
      "Kallman Gain, L:  [5. 5.]\n",
      "Analytically derived L:  [5. 5.]\n"
     ]
    }
   ],
   "source": [
    "C = np.array([1, 0])\n",
    "sig_w = 5\n",
    "S_w = q_k * np.ones((2,2))\n",
    "S_v = np.array([1])\n",
    "# R_k = r_k * np.ones((2,2))\n",
    "# Cov_p = sigma_p * np.ones((2,2))\n",
    "\n",
    "# Solve the continuous time ARE for \n",
    "Sigma = sp.linalg.solve_continuous_are(A.T, C.reshape(2,1), S_w, S_v )\n",
    "print(\"Steady state Sigma:\")\n",
    "print(Sigma)\n",
    "\n",
    "# Solve for Kallman gain L\n",
    "L = Sigma @ C.reshape(2,1) @ S_v\n",
    "print(\"Kallman Gain, L: \", L)\n",
    "\n",
    "# Check against analytic solution\n",
    "L_a = (2 + np.sqrt(4+sig_w)) * np.ones(2)\n",
    "print(\"Analytically derived L: \", L_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us simplify our control and Kallman gains further for the sake of coming notation, and say\n",
    "$$\n",
    "\n",
    "K = f \\begin{bmatrix}\n",
    "1 & 1 \n",
    "\\end{bmatrix} \\qquad \\text{ and } \\qquad L = d\\begin{bmatrix}\n",
    "1 \\\\ \n",
    "1 \n",
    "\\end{bmatrix}\n",
    "\n",
    "\n",
    "$$\n",
    "\n",
    "\n",
    "Putting all of this together, our full system dynamics become:\n",
    "$$\n",
    "\n",
    "\\begin{bmatrix}\n",
    "A & BK\\\\\n",
    "LC & A-LC-BK \n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "x \\\\ \n",
    "\\hat{x} \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\dot{x} \\\\ \n",
    "\\dot{\\hat{x}} \n",
    "\\end{bmatrix}\n",
    "\n",
    "$$\n",
    "\n",
    "Here $\\hat{x}$ is our extimate of $x$ from observation. This system is comes from these a synthesis of the following equations:\n",
    "$$\n",
    "\n",
    "\\begin{align*}\n",
    "\\dot{x} &= Ax + Bu & \\qquad u &= -K\\hat{x} \\\\\n",
    "\\dot{\\hat{x}} &= A\\hat{x} + Bu + L(y-\\hat{y}) & \\qquad y &= Cx \\\\\n",
    " & & \\qquad \\hat{y} &= C\\hat{x} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\n",
    "The last step in constructing this LQG system is to say that the closed loop controller has a nominal scalar gain, $m$. That brings our full system matrix to:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "A & mBK\\\\\n",
    "LC & A-LC-BK \n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 0 & 0\\\\\n",
    "0 & 1 & -mf & -mf\\\\\n",
    "d & 1 & 1-d & 1\\\\\n",
    "d & 0 & -d-f & 1-f\\\\\n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exposing Instability\n",
    "\n",
    "Recall that in dynamic systems, the primary requirment is that the eigenvalues of the system dynamics all be less than zero.  With that in mind, consider the charactaristic equation of our system matrix.\n",
    "$$\n",
    "\\lambda^4 + (d + f - 4)\\lambda^3 + (df - 2(d+f) + b)\\lambda^2 + (d+f - 4 + 2df(m-1))\\lambda +(1 + (1-m)df) = 0\n",
    "$$\n",
    "\n",
    "Focus on the final two terms (the only terms containing $m$).  Note that in order for all of the eigenvalues to be less than 0, these last two terms must be greater than 0.  \n",
    "$$\n",
    "\n",
    "\\begin{align*}\n",
    "1 + (1-m)df &> 0 & \\qquad d+f - 4 + 2df(m-1) &> 0 \\\\\n",
    "m &< 1 + \\frac{1}{df}  & \\qquad m &> \\frac{4 - d - f}{2df} + 1  \\\\\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\n",
    "When d and f (or equivalently, q and $\\sigma_w$) become sufficiently large, $ m \\gtrsim 1$ AND $m \\lesssim 1$.  Since, $g$ and $f$ cannot actually go to infinity, the system will technically be stable as long as it exhibits a gain of exactly one.  However, if it deviates slightly in either direction, it will become unstable! There is the rub: **An LQG system has no guarunteed stability margin.  It may operate arbitrarily close to a pole.** \n",
    "\n",
    "This is obviously not a desirable position to be in.  Most systems models involve at least some simplifications and/or approximations.  If any one of these cause the system to deviate slightly, they could through the system into unstable behavior.  How to approach this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition to Robust Control Theory\n",
    "\n",
    "The potential fragility of LQG systems act as a natural invitation to explore the field of robust controls.  In robust controls, we may learn to translate our system from state space into the frequency domain where we may map the gain and phase response of the system to perterbations. With this information we may learn how to trade some of LQG's optimality for improved stability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "1. J. Doyle, \"Guaranteed margins for LQG regulators,\" in *IEEE Transactions on Automatic Control*, vol. 23, no. 4, pp. 756-757, August 1978, doi: 10.1109/TAC.1978.1101812.\n",
    "2. Brunton, S. L., & Kutz, J. N. (2019). *Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control* (1st ed.). Cambridge University Press. [https://doi.org/10.1017/9781108380690](https://doi.org/10.1017/9781108380690)\n",
    "3. OpenAI. (2024). ChatGPT (v4). Retrieved from [https://www.openai.com](https://www.openai.com)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smvjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
